---
title: "Introduction to Workflow for Statistical Analysis"
author: "Christopher Gandrud"
institute: "Jena"
date: "2021-07-15 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [robot, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
library(tidyverse)
theme_set(theme_minimal())
```

# üìù Lesson Preview

- What is a workflow?

- Why reproducible research?

- Reproducible research workflow

- Why R (or other programmatic approach to statistical analysis)?

- Automation/Effort trade off

---

class: inverse, center, middle

# In your research . . .

---

# ü§î In your research:

- do you plan to **repeat** the task?

- do you want others to be able to **replicate** your data collection process?

- does the data task have **non-trivial** scope and complexity?

---

class: inverse, centre, middle

# . . . ‚òùÔ∏è then a reproducible statistical workflow is for you.

---

class: inverse, centre, middle

# ‚ç∞ What is a workflow?

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Work Execution

In quantitative methods courses, we usually learn about **work execution**. For example, 

- transforming a data set to make it useable by a model

- applying a statistical procedure to a data set

- reasoning about the results of a statistical procedure

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Workflow

But having an effective **workflow** is critical. A workflow is:

> the process by which work is selected and organised for execution.

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Not covered in this course: 

**Prioritisation**

This course does not cover how you select projects and prioritise avenues of investigation, though this is crucial for a project's success.

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Covered in this course

**Tools for automating research execution**

This course does cover the programmatic tools for automating research execution.

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Programmatic

> a task done through computer program **code**. It is repeatable and not manual.

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

# Ideally our programs are **extensible**

> designed to be used not just with data we have seen, but also new data.

Our workflow should be **extensible** as well to many different statistical research projects.

---

class: inverse, centre, middle
background-color: #FFC400
color: #24292F

Programmatic and reproducible statistical research workflows are valuable.

---

# üéì Academic

- Skills needed to do **original quantitative research** for your **research**.

- State-of-the-art tools needed for **future high-level academic research**.

    + Take advantage of new data sources

    + Avoid effort duplication

    + Make your research reproducible

---

---

# üèï NGOs

NGO's are becoming increasingly data-oriented and need people with **skills** to
**handle and analyse** this data.

Ex. Former Hertie Master's students co-founded
[CorrelAid](http://correlaid.org/) to assist NGOs with data analysis.

---

# üè≠ Industry 

Automated data collection and retrieval **scales**.

We don't just want to solve a customer problem once, we want to solve it many times with the **marginal cost decreasing** each additional time we solve the problem.

```{r return-to-scale, echo=FALSE, fig.height = 2.5, dpi=300}
x <- seq(1, 10, 0.01)
returns_to_scale <- tibble(x = x, y = x^-2)

ggplot(returns_to_scale, aes(x, y)) +
  geom_line(color = "pink", size = 1) +
  xlab("Quantity produced") + ylab("Cost of production\n") +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()
        )
```

---

# üè≠ Industry 

<br>
<br>
<br>

> "It's not interesting if it doesn't scale." -- Jim Freeman

---

# üè≠ Industry 

So, being able to scale data science--automate data retrieval and management--is highly valued. E.g. on [PayScale](https://www.payscale.com/research/DE/Job=Data_Scientist/Salary):

```{r pay-by-experience, echo=FALSE}
knitr::include_graphics("img/pay-by-experience.png")
```

---

class: inverse, centre, middle

# ‚ç∞ Why reproducible research?

---

class: inverse, centre, middle
background-color: #FF8C03

# ‚ç∞ What is reproducible research?

---

class: inverse, centre, middle
background-color: #FFC400

#  Really reproducible research

> the data and code used to make a finding are **available** and they are **sufficient** for an independent researcher to **recreate the finding** (Peng 2011, 1226)

Make available the research, **not just the advertising** for the findings (e.g. papers, book).

---

# Reproducibility vs. Replication

**Reproducibility**: an independent study makes the same findings using the
**same data** and **code** as the original researchers.

**Replicability**: an independent study makes the same conclusions as the original
using **other** data, code, and even methods,
i.e. independent verification.

---

# Reproducibility vs. Replication

> ''A study can be reproducible and still be wrong'' [Peng 2014](http://simplystatistics.org/2014/06/06/the-real-reason-reproducible-research-is-important/).

E.g. a finding that is statistically significant in one study may remain statistically
significant when reproduced using the original data/code, but **replication studies
are unable to find a similar result**.

The original finding could just have been
[noise](http://andrewgelman.com/2014/09/03/disagree-alan-turing-daniel-kahneman-regarding-strength-statistical-evidence/).

---

# Why reproducibility?

- **Replication** is the ''**ultimate standard**'' for judging scientific claims (Peng 2011).

- **Reproducibility**

    + **Enhances replication** (other researchers can understand how an analysis
    was actually done)

    + Is a **minimum standard** for judging scientific claims when replication is
    not possible.

---

# Why reproducibility?

Reproducibility helps **avoid effort duplication**:

- Others **don't waste time**:

    + Gathering data that has already been gathered.

    + Discovering procedures that have already been discovered.

---

# Why reproducibility?

- Reproducibility also makes it possible to **find and correct errors**.

- Recent examples:
    - Translation errors in the
    [World Values Survey](http://www.washingtonpost.com/blogs/monkey-cage/wp/2014/09/02/world-values-lost-in-translation/).

    - Data errors in research on
    [intestinal worm treatment and school attendance](http://www.columbia.edu/~mh2245/w/worms.html).

    - [L'Affaire LaCour](http://www.vox.com/2015/5/20/8630535/same-sex-marriage-study):
    data *fabrication* discovered.

- Data errors can cause spurious findings that ultimately **waste researchers time**,
because they try to explain 'wrong' findings.

---

# Why reproducibility?

- **Higher research impact**

    + Reproducible research is likely to be more **useful for other researchers**.
    They can use your data and learn from your code and methods.

    + More use ‚Üí more impact (e.g. citations)

- **Better work habits**

    + Thinking about reproducibility from the beginning makes your files
    **better organised** and your work is **better documented**.

    + This allows you to **build on your own work** more effectively.

---

# Reproducible research workflow

.center[
```{r rep-flow, echo=FALSE, out.width="70%"}
knitr::include_graphics("img/rep-research-workflow.png")
```
]

.small[from Gandrud (2020, 25)]
---

# Practical tips for reproducible research

- ‚úèÔ∏è Document Everything!

- üìÑ Everything is a (text) file.

- ü§ì All files should be human readable.

- ‚ãà Explicitly tie your files together.

- üóÇ Have a plan to organise, store, and make your files available.

---

class: inverse, center, middle

# Personal data privacy

---

class: inverse, center, middle
background-color: #000000

# üèõ Ethical data retrieval and management

> Privacy and data protection are fundamental rights, which need to be protected. ([EUI 2019](https://www.eui.eu/Documents/ServicesAdmin/DeanOfStudies/ResearchEthics/Guide-Data-Protection-Research.pdf))

---

# Always. . .

Consider the needs for privacy and protecting persons' data.

‚ö†Ô∏è It is especially important for automated data retrieval and management to **build in** privacy and data protection. 

‚ö†Ô∏è Automated data retrieval and management scale. If done poorly, can **scale privacy infringements**. 

---

# (some) Good practices

**üëç Do**

- Follow your institution's **data protection policies**.

- Clearly **document** all of the data you have, your justification for having it, how you maintain and delete it.

- If you handle personal data, **test** that all of your data pipelines don't "leak" the data before you include personal data in it.

- Regularly **review** what data you have and your reason for  having it.

**‚ö†Ô∏è Don't**

- ‚ö†Ô∏è **Never store** personally identifiable data in non-secure locations

- ‚ö†Ô∏è **Never transport** personally identifiable data in non-secure ways (e.g. email)

- ‚ö†Ô∏è **Never store** credentials in non-secure locations

---

# ‚ö†Ô∏è How much effort should you give to automating your workflow?

```{r echo=FALSE, out.width="75%"}
knitr::include_graphics("https://imgs.xkcd.com/comics/is_it_worth_the_time.png")
```

---

# Assumptions behind xkcd framework

JD Long [highlights](https://twitter.com/CMastication/status/1390752830177398785) key assumptions behind this framework that might not hold:

- All time is the same value -> but time right before a deadline might be more valuable than other time

- Automated work is the same quality as non-automated: the process of automation often improves quality (e.g. increases reproducibility)

- The frequency of doing a process stays the same after it is automated: automation makes it easier to do the process again -> you do it more

---

# üëÄ Course content preview

- Introduction to statistical workflows & Introduction to R Programming 1 (9:00-10:30)
    
- Introduction to R programming 2 (11:00-12:30)

- Introduction to Programmatic Files Structures (13:30-15:00)
    
- Introduction to Rmarkdown and Literate Programming (15.30-17:00)

---

class: inverse, center, middle
background-color: #FB3579

## We are only scratching the surface of what is possible (and needed). Aim: you know where to start.

---

class: inverse, center, middle
background-color: #FB3579

To prepare: we will build up to converting one of your research projects to a reproducible statistical workflow.
